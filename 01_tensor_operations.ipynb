{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monika171/Deep-Learning-with-Pytorch/blob/main/01_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY4aPt97fShc"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1m5CRvySZxhn5TLxItOM-8Dp3ivE-anS3')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7hkf7E1eB4f"
      },
      "source": [
        "#  <font color=red><u>__5 IMPORTANT *MUST KNOW* PyTorch TENSOR FUNCTIONS!__</u></font>\n",
        "\n",
        "### <font color=red><b> _PyTorch is a Deep Learning framework introduced by Facebook and is based on Torch library. It is basically a replacement for *NumPy* to use the power of GPUs.<br><br>Tensors are similar to *NumPy’s ndarrays*, with the addition being that Tensors can also be used on a GPU to accelerate computing.<br><br>Here we will look into five most common yet important tensor functions:_ </b></font>\n",
        "\n",
        "- ### <font color=red><b>_TORCH.ISNAN_</b></font>\n",
        "- ### <font color=red><b>_TORCH.SORT_</b></font>\n",
        "- ### <font color=red><b>_TORCH.UNIQUE_</b></font>\n",
        "- ### <font color=red><b>_TORCH.HISTC_</b></font>\n",
        "- ### <font color=red><b>_TORCH.SAVE_</b></font>\n",
        "\n",
        "\n",
        "*Before we begin, let's install and import PyTorch.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkHGID2NeB4f"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzvUSRwdeB4f"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBx9odYkeB4f"
      },
      "source": [
        "***\n",
        "## <a id=\"function1\"><font color=green><u>Function 1</u> - TORCH.ISNAN</font></a>\n",
        "\n",
        "> Returns a tensor representing if each element of `input` is `NaN` or not. The returned tensor is a new tensor with boolean elements.\n",
        "\n",
        "> **Note:** Complex values considered NaN when either their real and/or imaginary part is NaN.\n",
        "\n",
        "##### <u>Format</u>:\n",
        "```\n",
        "torch.isnan(input)\n",
        " ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGAb7L-5eB4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb58eb48-ba4c-498b-ed36-f505d2f65308"
      },
      "source": [
        "# Example 1 - working\n",
        "torch.isnan(torch.tensor([23, 44., 5, float('nan'), 0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False,  True, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlvHUVpXeB4g"
      },
      "source": [
        "> Only the fourth element is `NaN` here, rest even when zero is not considered a NaN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb1th9BSeB4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91df2e8-6590-4c89-f376-a927169ef38f"
      },
      "source": [
        "# Example 2 - working\n",
        "torch.isnan(torch.tensor([np.nan, float('nan')+1j, 52+0j, float('inf')]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7TtQQQUeB4g"
      },
      "source": [
        "> As mentioned earlier, complex values considered NaN when either their real and/or imaginary part is NaN and here in second element, the real part is `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MLG1ClTeB4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "1317056d-3023-4df9-fdd0-a5e58b90d6bd"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "x = np.array([[1,2],[3,4.]])\n",
        "# x = torch.from_numpy(x)\n",
        "\n",
        "torch.isnan(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-20ae5621becb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# x = torch.from_numpy(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: isnan(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex1QLuy0eB4g"
      },
      "source": [
        "> `input` argument must always be a tensor.<br>\n",
        "> <u>Hence, Correction:</u><br>\n",
        "> `x = np.array([[1,2],[3,4.]])`<br>\n",
        "> `x = torch.from_numpy(x)`<br>\n",
        "> `torch.isnan(x)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clUZVMAleB4g"
      },
      "source": [
        "### <u>Summary</u>:\n",
        "* A Pytorch-internal procedure to detect NaNs in Tensors works on the GPU as well as on the CPU.\n",
        "* `\n",
        "torch.isnan(input)\n",
        " ` is very useful when issues arise during backward pass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrjF6EeOeB4g"
      },
      "source": [
        "Let's save our work using Jovian before continuing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpMHtfX4eB4g"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLX1Icv1eB4g"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPdTkI8LeB4g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "63544ab3-cf68-437d-a6ab-02f9957cf9c4"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBXFSD9neB4h"
      },
      "source": [
        "***\n",
        "## <a id=\"function2\"><font color=green><u>Function 2</u> - TORCH.SORT</font></a>\n",
        "\n",
        "> Sorts in ascending order(by value)along a given dimension.\n",
        "\n",
        "> If `dim` is not given, the last dimension of the input is chosen.\n",
        "\n",
        "> For descending order (by value) set `descending` to `True`.\n",
        "\n",
        "##### <u>Format</u>:\n",
        "```\n",
        "torch.sort(input, dim=-1, descending=False, *, out=None)\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEe_CBFneB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d90df92-8392-4159-b00a-08bf922f0ffc"
      },
      "source": [
        "# Example 1 - working\n",
        "x = torch.tensor([[78,30,77],[91,16,25],[55,180,101]])\n",
        "print(x)\n",
        "sorted, indices = torch.sort(x)\n",
        "print(sorted)\n",
        "print(indices)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 78,  30,  77],\n",
            "        [ 91,  16,  25],\n",
            "        [ 55, 180, 101]])\n",
            "tensor([[ 30,  77,  78],\n",
            "        [ 16,  25,  91],\n",
            "        [ 55, 101, 180]])\n",
            "tensor([[1, 2, 0],\n",
            "        [1, 2, 0],\n",
            "        [0, 2, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al1yEwEAeB4h"
      },
      "source": [
        "> Since `dim` wasn't mentioned here, the last dimension of the input is chosen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXoG32zzeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26853560-b46c-40f7-fe54-309366afb7d5"
      },
      "source": [
        "# Example 2 - working\n",
        "x1 = torch.tensor([[78,30,77],[91,16,25],[55,180,101]])\n",
        "print(x1)\n",
        "sorted, indices = torch.sort(x1, dim=0)\n",
        "print(sorted)\n",
        "print(indices)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 78,  30,  77],\n",
            "        [ 91,  16,  25],\n",
            "        [ 55, 180, 101]])\n",
            "tensor([[ 55,  16,  25],\n",
            "        [ 78,  30,  77],\n",
            "        [ 91, 180, 101]])\n",
            "tensor([[2, 1, 1],\n",
            "        [0, 0, 0],\n",
            "        [1, 2, 2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn51li9YeB4h"
      },
      "source": [
        "> When `dim=0`, sorting is done columnwise i.e. along the first axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twlk2zT5eB4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7ab3e6d9-222c-4204-8ffe-6a6115ee6922"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "x3 = torch.tensor([[78,30,77],[91,16,25],[55,180,101]])\n",
        "print(x3)\n",
        "sorted, indices = torch.sort(x3, dim=2)\n",
        "print(sorted)\n",
        "print(indices)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 78,  30,  77],\n",
            "        [ 91,  16,  25],\n",
            "        [ 55, 180, 101]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8947c8184b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m78\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m77\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m91\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kngmOc8LeB4h"
      },
      "source": [
        "> Error says \"Dimension out of range\" i.e. in our example, value of `dim` exceeds max value of 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUW57GhZeB4h"
      },
      "source": [
        "### <u>Summary</u>:\n",
        "* This function sorts along a given dimension in any order mentioned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4ZuocsmeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "7c1e9b60-6e4a-41bc-db23-b7dcbc671903"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ2g83z5eB4h"
      },
      "source": [
        "***\n",
        "## <a id=\"function3\"><font color=green><u>Function 3</u> - TORCH.UNIQUE</font></a>\n",
        "\n",
        "> This function returns the unique elements of the input tensor.\n",
        "\n",
        "##### <u>Format</u>:\n",
        "```\n",
        "torch.unique(*args, **kwargs)\n",
        " ```\n",
        "\n",
        "##### <u>Parameters</u>:\n",
        "* input (Tensor) – the input tensor\n",
        "\n",
        "* sorted (bool) – Whether to sort the unique elements in ascending order before returning as output.\n",
        "\n",
        "* return_inverse (bool) – Whether to also return the indices for where elements in the original input ended up in the returned unique list.\n",
        "\n",
        "* return_counts (bool) – Whether to also return the counts for each unique element.\n",
        "\n",
        "* dim (int) – the dimension to apply unique. If `None`, the unique of the flattened input is returned. default: `None`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkMuIQleB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001a99ab-c5d1-490a-d4ba-5c12f6119aef"
      },
      "source": [
        "# Example 1 - working\n",
        "output, inverse_indices = torch.unique(torch.tensor([[16, -3], [-3, 11]], dtype=torch.long), sorted=True, return_inverse=True)\n",
        "print(output)\n",
        "print(inverse_indices)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-3, 11, 16])\n",
            "tensor([[2, 0],\n",
            "        [0, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPQvYQi1eB4h"
      },
      "source": [
        "> Here `sorted=True` sorts the final unique elements in ascending order in output.\n",
        "> Also, `return_inverse = True` returns the indices of elements in final output and here by default `dim = None`, so the unique value of the flattened input is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_oO7ZOjeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "658c264d-6ed8-42a7-892b-6269b6ecd49f"
      },
      "source": [
        "# Example 2 - working\n",
        "x = torch.tensor([[0, 8, 8],\n",
        "                  [0, 1, 1],\n",
        "                  [0, 8, 8],\n",
        "                  [0 ,8, 6]])\n",
        "print(torch.unique(x, sorted=True, dim=1))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 8, 8],\n",
            "        [0, 1, 1],\n",
            "        [0, 8, 8],\n",
            "        [0, 6, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hIiKjgceB4h"
      },
      "source": [
        "> On `dim=1` there is double occurrence of the numbers `8 , 1, 8` in the first three rows respectively as `Numpy` and `PyTorch` does this to preserve the shape of the final result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oI-eFoAeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "f649bee0-3232-4996-813e-af7a8f9c8336"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "x1 = torch.tensor([[0, 8, 8],\n",
        "                  [0, 1, 1],\n",
        "                  [0, 8, 8],\n",
        "                  [0 ,8, 6]])\n",
        "result, inverse_indices, counts = torch.unique(x, True, True, True, True, dim=0)\n",
        "print(result)\n",
        "print(inverse_indices)\n",
        "print(counts)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-047fdbe5f1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   [0 ,8, 6]])\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdispatch_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdispatch_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _unique_impl() got multiple values for argument 'dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVJvt1PteB4h"
      },
      "source": [
        "> There is too many arguments according to format.\n",
        "\n",
        "> The correct syntax would be:\n",
        "* `result, inverse_indices, counts = torch.unique(x, True, True, True, dim=0)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTM1t_tteB4h"
      },
      "source": [
        "### <u>Summary</u>:\n",
        "* Currently in the CUDA implementation and the CPU implementation when *dim* is specified, *torch.unique* always sort the tensor at the beginning regardless of the sort argument. \n",
        "\n",
        "* this `unique` function can sometimes give different results as we noticed in example 2, because of padding.\n",
        "\n",
        "* Use `torch.unique()` to get common items between tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah2f2fwLeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "907ea591-0799-40c0-e99d-809a4baf5171"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXAhPNereB4h"
      },
      "source": [
        "***\n",
        "## <a id=\"function4\"><font color=green><u>Function 4</u> - TORCH.HISTC</font></a>\n",
        "\n",
        "> Computes the histogram of a tensor.\n",
        "\n",
        "> The elements are sorted into equal width bins between `min` and `max`. If `min` and `max` are both zero, the minimum and maximum values of the data are used.\n",
        "\n",
        "> Elements lower than min and higher than max are ignored.\n",
        "\n",
        "##### <u>Format</u>:\n",
        "```\n",
        "torch.histc(input, bins=100, min=0, max=0, *, out=None)\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPDesYk9eB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e00624a-c6bf-4fca-cfcc-1e1924208a53"
      },
      "source": [
        "# Example 1 - \n",
        "torch.histc(torch.tensor([7, 5., 7]), bins=4, min=0, max=8)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 1., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQLqVZo4eB4h"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtKMdzmeB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c77ad6-b2e8-4310-cf77-3f52fa3d2f70"
      },
      "source": [
        "# Example 2 - working\n",
        "torch.histc(torch.tensor([15., 65, 15, 101]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFH6nrT1eB4h"
      },
      "source": [
        "> Since `bins` value is not provided, by default the elements are sorted into 100 equally spaced bins between the minimum and maximum values of `input`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DihgPLz9eB4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "24bf42d8-b580-4484-b202-ed6e26105c7e"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.histc(torch.tensor([53., 9, 53., 17, 17, 17, 23]), bins=5.0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-703b0d75ef93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m53.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m53.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: histc(): argument 'bins' must be int, not float"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPK05T53eB4h"
      },
      "source": [
        "> in this function arguments `bins`, `min`, `max` must be int and NOT float.\n",
        "\n",
        "> Hence, corrected form will be:\n",
        "\n",
        "> `torch.histc(torch.tensor([53., 9, 53., 17, 17, 17, 23]), bins=5.0)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrZ3sYZweB4i"
      },
      "source": [
        "### <u>Summary</u>:\n",
        "* torch.histc(x) returns a histogram of the elements in x e.g: sampling in a training batch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QljanPcYeB4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "04e4bc26-c190-4ad2-afc7-0eb36592f88b"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwma-nD-eB4i"
      },
      "source": [
        "***\n",
        "## <a id=\"function5\"><font color=green><u>Function 5</u> - TORCH.SAVE</font></a>\n",
        "\n",
        "> Saves an object to a disk file.\n",
        "\n",
        "> This saves a serialized object to disk. It uses python's pickle utility for serialization. Models, tensors and dictionaries can be saved using this function.\n",
        "\n",
        "\n",
        "##### <u>Format</u>:\n",
        "```\n",
        "torch.save(obj, f: Union[str, os.PathLike, BinaryIO], pickle_module=<module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'>, pickle_protocol=2, _use_new_zipfile_serialization=True)\n",
        " ```\n",
        "\n",
        "##### <u>Parameters</u>:\n",
        "* obj – saved object\n",
        "\n",
        "* f – a file-like object (has to implement write and flush) or a string or os.PathLike object containing a file name\n",
        "\n",
        "* pickle_module – module used for pickling metadata and objects\n",
        "\n",
        "* pickle_protocol – can be specified to override the default protocol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTNAVN0ieB4i"
      },
      "source": [
        "# Example 1 - working\n",
        "# Save to file\n",
        "x = torch.tensor([10, 17, 72, 23, 6])\n",
        "torch.save(x, 'tensor.pt')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw_9Ysq7eB4i"
      },
      "source": [
        "> A common PyTorch convention is to save tensors using `.pt` file extension.\n",
        "\n",
        "> This makes a ‘tensor.pt’ file in the working directory and it contains the model architecture as well as the saved weights (if exists).\n",
        "\n",
        "> We can load the saved file/model using the function below. Loading is as simple as Saving. In case of model, we do not even need to define the model architecture as the information about the model architecture is already stored in the saved file.\n",
        "\n",
        "> * `torch.load()`: This function uses pickle's unpickling facilities to deserialize pickled object files to memory and also facilitates the device to load the data into.\n",
        "\n",
        "> * `y = torch.load('tensor.pt')`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJd-3ZWjeB4i"
      },
      "source": [
        "# Example 2 - working\n",
        "# Save to io.BytesIO \n",
        "import io\n",
        "buffer = io.BytesIO()\n",
        "torch.save(x, buffer)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb0DKNGKeB4i"
      },
      "source": [
        "> Just like what we do with variables, data can be kept as bytes in an in-memory buffer when we use the io module’s Bytes IO operations.\n",
        "\n",
        "> **Note:** You need to seek to the beginning of the buffer before reading:\n",
        "\n",
        "> * `buffer.seek(0)`\n",
        "\n",
        "> * `print(buffer.read())`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YLhUd_deB4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "670d4d41-f041-49d0-853d-8357e3db93c9"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "z = torch.tensor([9, 3, 19, 24, 5])\n",
        "torch.save(z)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4444c622cc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: save() missing 1 required positional argument: 'f'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9kU9XhneB4i"
      },
      "source": [
        "> An important argument *Path* is missing. To make it work, insert *PathLike* object containing a file name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8CNj248eB4i"
      },
      "source": [
        "### <u>Summary</u>:\n",
        "\n",
        "* We can also save an entire model i.e. architecture of a model as well as its weights, so that we can resume from the point where we had frozen all but the last layer.\n",
        "\n",
        "* If you are working on a hosted environment it’s always better to save the model in cloud storage, so that later its easier to load your model without having to upload it which may take time because the models are usually of big size.\n",
        "\n",
        "* Also if you plan to deploy your model in an app on the web, saving in cloud is better because it allows you to make tweaks and changes, put your model to test and perform faster iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxrxdEMDeB4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "a65aaca9-c84d-4f6a-8c6f-dcf930fbf6da"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX_zb1nseB4i"
      },
      "source": [
        "## <font color=blue><u>__Conclusion__</u></font>\n",
        "<font color=red>_Functions such as \n",
        "`TORCH.ISNAN`, `TORCH.SORT`, `TORCH.UNIQUE`, `TORCH.HISTC ` and `TORCH.SAVE` were discussed in this notebook. Various examples and uses of each individual functions were also discussed. This notebook can help us better understand other advanced functions such as *nansum*, *nanquantile*, *unique_consecutive*, *argsort*, *searchsorted*, *saving-loading-tensors* etc._</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iL2UQC6eB4i"
      },
      "source": [
        "## <font color=blue><u>__Reference Links__</u></font>\n",
        "\n",
        "* [Official documentation for tensor operations](https://pytorch.org/docs/stable/torch.html)\n",
        "* [Pytorch Operation to detect NaNs](https://www.mmbyte.com/article/74581.html)\n",
        "* [Saving/Loading your model in PyTorch](https://medium.com/udacity-pytorch-challengers/saving-loading-your-model-in-pytorch-741b80daf3c)\n",
        "* [Everything You Need To Know About Saving Weights In PyTorch](https://towardsdatascience.com/everything-you-need-to-know-about-saving-weights-in-pytorch-572651f3f8de)\n",
        "*[How to save and reload a deep learning model in Pytorch?](https://www.dezyre.com/recipes/save-reload-deep-learning-model-pytorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDY4IxXeB4i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "4f628099-336a-4096-d676-ea7429432be0"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations-monika171')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/monika171/01-tensor-operations-monika171\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/monika171/01-tensor-operations-monika171'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zNNIlCueB4i"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}